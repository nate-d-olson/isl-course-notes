---
title: "Chapter 3 Exercises"
author: "Nate Olson"
date: "February 2, 2016"
output: html_document
---
```{r}
library(MASS)
library(ISLR)
library(dplyr)
library(tidyr)
library(stringr)
library(purrr)
library(broom)
library(ggplot2)
```


Applied
8. 
```{r}
data("Auto")
fit <- lm(mpg~horsepower, data = Auto)
```

```{r}
summary(fit)
```

a.
i - yes there is a relationship between the predictor and response
ii - the replationship is significant
iii - relationship is negative
iv - predicted mpg
```{r}
pred_fit <- data_frame(horsepower = 95:105)
pred_val <- predict(fit,interval = "prediction", newdata = pred_fit) %>% 
    as.data.frame() %>%  bind_cols(pred_fit) %>% filter(horsepower == 98)
pred_val 
```
note use of interval = "prediction" for 95% CI

```{r}
ggplot(Auto) + geom_point(aes(x = horsepower, y = mpg)) + 
    geom_abline(aes(slope = fit$coefficients['horsepower'], 
                    intercept = fit$coefficients['(Intercept)']))
```

Residuals and scale-location have u-shape, though the standardized residuals are normally distributed, leverage increases with Standardized residual values
```{r}
par(mfrow=c(2,2))
plot(fit)
par(mfrow=c(1,1))
```

#### 9
A. Scatter plot with all Auto variables
```{r}
#library(GGally)
#ggpairs(Auto)
plot(Auto)
```

B. Calculate correlations between variables
```{r}
Auto %>% select(-name) %>% cor()
```

C. Fit regression to auto data without name
```{r}
fit <- lm(mpg~. - name, data = Auto)
summary(fit)
```

There is a relationship, predictors origin, year, weight, and displacement have a significant effect. Year coefficient suggests that mgp is positively correlated with year.

```{r}
par(mfrow=c(2,2))
plot(fit)
par(mfrow=c(1,1))
```

Leverage plot outliers 327, 394, and 14

E. Fitting models with interactions
```{r}
nameless_auto <- Auto %>% select(-name)
fit <- lm(mpg~cylinders*displacement*horsepower*weight*acceleration*year + origin,
          data = nameless_auto)
summary(fit)
```

Did not test for interactions with origin as confounded with other variables creating sigularities. 
```{r}
par(mfrow=c(2,2))
plot(fit)
par(mfrow=c(1,1))
```
None of the interactions apprear significant when looking at all

When decreasing the number of interactions more factors become significant.
```{r}
fit <- lm(mpg~cylinders*displacement*horsepower+weight+acceleration+year + origin,
          data = nameless_auto)
summary(fit)
```

```{r}
par(mfrow=c(2,2))
plot(fit)
par(mfrow=c(1,1))
```

F. Testing different transformations
```{r}
fit <- lm(log(mpg)~.,
          data = nameless_auto)
summary(fit)
```

```{r}
par(mfrow=c(2,2))
plot(fit)
par(mfrow=c(1,1))
```

log improves R^2, decreases smile in Resibule plot

```{r}
fit <- lm(sqrt(mpg)~.,
          data = nameless_auto)
summary(fit)
```

```{r}
par(mfrow=c(2,2))
plot(fit)
par(mfrow=c(1,1))
```

sqrt btter fit but not as good as log

```{r}

fit <- lm(mpg^2~.,
          data = nameless_auto)
summary(fit)
```

```{r}
par(mfrow=c(2,2))
plot(fit)
par(mfrow=c(1,1))
```
Log still the best.

Looking at interactions again but with log transformation
```{r}
fit <- lm(mpg~I(log(cylinders))*I(log(displacement))*I(log(horsepower))*I(log(weight))*I(log(acceleration))*I(log(year)) + origin,
          data = nameless_auto)
summary(fit)
```

Did not test for interactions with origin as confounded with other variables creating sigularities. 
```{r}
par(mfrow=c(2,2))
plot(fit)
par(mfrow=c(1,1))
```

10. 
A. 
```{r}
fit <- lm(Sales~Price*Urban*US, data = Carseats)
summary(fit)
fit <- lm(Sales~Price+Urban+US, data = Carseats)
summary(fit)
```

b. Interpretation of coefficients
Intercept - sale of non-urban, non-US, cars with a sales price of 0
Price - impact of price on non-urban and non-us car (fixed values), car sales decrease with increasing car price
UrbanYes - For a fixed price there are few urban cars sold than non-urban
USYes - For a fixed price and region more cars are sold in the US than non-US countries

c. See notes
d. Price, Urban, and US when not accounting for interactions, but only price when accounting for interactions.
e. 
```{r}
fit <- lm(Sales~Price, data = Carseats)
summary(fit)
```
f. 
```{r}
par(mfrow=c(2,2))
plot(fit)
par(mfrow=c(1,1))
```

```{r}
ggplot(Carseats) + geom_point(aes(x = Price, y = Sales, color = Urban, shape = US)) + geom_abline(aes(intercept = fit$coefficients['(Intercept)'],slope = fit$coefficients['Price'] ))
```

h. Yes there is evidence of high leverage points and potentially outliers.

11. 
```{r}
set.seed(1)
x = rnorm(100)
y = 2*x+rnorm(100)
```

a. 
```{r}
fit <- lm(y~x + 0)
summary(fit)
```

How are they different 2X slope?
For the two to be equal the slope should equal 1.

b. 
```{r}
fit <- lm(y~x)
summary(fit)
```

```{r}
plot(x,y)
abline(fit)
```

c. Very similar results except that slope is slightly less negative when allowing the intercept to not equal 0.

d. to do work out math
e. comparison of x~y and y~x
```{r}
fit <- lm(x~y)
summary(fit)
```

12. 
